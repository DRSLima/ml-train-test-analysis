{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandsOn3 - BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DRSLima/sentiment-analysis-twitter/blob/master/Text%20Classification%20with%20BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJJRtUb_QtFk",
        "colab_type": "code",
        "outputId": "55aba538-fc1d-4f7e-9597-e84ceebf091b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 57.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=0b58c3bbd449563d265474e81629c5dda18c4b7de7e73c3e27e93fdb2ba7cabb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98dz7R9Qq4S",
        "colab_type": "code",
        "outputId": "0f820b96-8eed-474f-b27d-4ad45251e432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train = pd.read_csv('https://raw.githubusercontent.com/jpvmm/FASAM_NLP/master/train_sample.csv')\n",
        "\n",
        "#Vamos ter usar o subset menor pois a memória do notebook não vai aguentar.\n",
        "df_train = df_train[0:10000]\n",
        "\n",
        "\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/jpvmm/FASAM_NLP/master/test_sample.csv')\n",
        "\n",
        "df_test = df_test[0:500]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMuw9AFNHIk",
        "colab_type": "text"
      },
      "source": [
        "# **Começando os trabalhos**\n",
        "\n",
        "\n",
        "---\n",
        "**Pergunta**: Como podemos trabalhar com duas linguages diferentes? Qual estratégia poderia ser adotada utilizando o BERT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulpwhoOZROsy",
        "colab_type": "text"
      },
      "source": [
        "## **Utilizando DistilBERT**\n",
        "\n",
        "Vamos utilizar o DistilBERT da biblioteca Transformers HuggingFace.\n",
        "\n",
        "Aqui utilizaremos o modelo multilingual pré treinado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F35-jTTYM1u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-multilingual-cased')\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "modelo = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEax0xOqSQs9",
        "colab_type": "text"
      },
      "source": [
        "### **Limpeza e Tokenização**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlM15JbXTMz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df_train['title']\n",
        "y = df_train['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eccJfavUTXJJ",
        "colab_type": "code",
        "outputId": "893785c6-e8c0-4fda-c47d-063c9c564e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Limpeza de dados\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def limpaTexto(texto):\n",
        "\n",
        "  tokens = texto.split()\n",
        "\n",
        "  #Regex para filtro de caracteres\n",
        "  re_puc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "  #Remoção de pontuação\n",
        "  tokens = [re_puc.sub('', w ) for w in tokens]\n",
        "  #Remoção de tokens não alfabéticos\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  #Remoção de stopwords\n",
        "  stop_words1 = set(stopwords.words('portuguese'))\n",
        "  stop_words2 = set(stopwords.words('spanish'))\n",
        "\n",
        "  tokens = [w for w in tokens if not w in stop_words1]\n",
        "  tokens = [w for w in tokens if not w in stop_words2]\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  tokens = ' '.join(tokens)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "x = x.apply(limpaTexto)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLeMChn3lsdx",
        "colab_type": "code",
        "outputId": "5b9aa018-5c7c-44ff-eedd-359b9c503fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#Visualizando como o BERT tokenizer sentenças\n",
        "#Wordpiece tokenization\n",
        "\n",
        "for i in range(3):\n",
        "  print(x[i], '---->', tokenizer.tokenize(x[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Microscópio Biológico Binocular Meopta Profissional ----> ['micro', '##sco', '##pio', 'bio', '##logico', 'bin', '##oc', '##ular', 'me', '##op', '##ta', 'profissional']\n",
            "Nissan Versa ----> ['ni', '##ssa', '##n', 'vers', '##a']\n",
            "Llave Contacto Yamaha Fz Tapa Tanque Mpr ----> ['ll', '##ave', 'contacto', 'ya', '##mah', '##a', 'f', '##z', 'tapa', 'tan', '##que', 'm', '##pr']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J-iMGw_Rn_7",
        "colab_type": "code",
        "outputId": "ccd5d2b3-3f4c-44ed-85da-e87f9afc7569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "tokenized = x.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "for i in range(3):\n",
        "  print(x[i],'--->', tokenized[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Microscópio Biológico Binocular Meopta Profissional ---> [101, 54396, 22402, 22196, 12297, 59361, 16292, 25125, 18062, 10911, 13362, 10213, 40604, 102]\n",
            "Nissan Versa ---> [101, 10414, 11253, 10115, 12576, 10113, 102]\n",
            "Llave Contacto Yamaha Fz Tapa Tanque Mpr ---> [101, 22469, 23641, 45620, 10549, 56271, 10113, 174, 10305, 89711, 15176, 11189, 181, 52302, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_ag4JNSWR3",
        "colab_type": "code",
        "outputId": "26ed5972-190d-4e9f-c458-b3f320a884c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Criando o padding\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "padded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sftQZb_JUwi9",
        "colab_type": "text"
      },
      "source": [
        "### **Masking**\n",
        "pesquisar isso aqui"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbjWqlNUZiz",
        "colab_type": "code",
        "outputId": "47bc1590-1b08-43d3-86b6-2a6a8cb1a6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nk8jm7VJm1d",
        "colab_type": "text"
      },
      "source": [
        "### **BERT Embeddings**\n",
        "\n",
        "Os embeddings do BERT são gerados a partir de sua última camada. \n",
        "\n",
        "Como estamos trabalhando com uma tarefa de classificação, apenas a posição com o token CLS é a que no interessa, pois é a posição da tarefa de classificação do BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lza4voWtUsgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = modelo(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTiXXd_uA7L2",
        "colab_type": "code",
        "outputId": "3771a465-d158-4260-dd57-9b83682e0595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_hidden_states[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6_32xY6LmZh",
        "colab_type": "text"
      },
      "source": [
        "**Pegando apenas o vetor de primeira posição na saída**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UGScNpxBEwu",
        "colab_type": "code",
        "outputId": "df7963f3-b18f-4434-aa2f-f155458b4299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ax1_sDLz3k",
        "colab_type": "text"
      },
      "source": [
        "## **Modelo de Classificação**\n",
        "\n",
        "Para realizar a tarefa de classificação, vamos utilizar um modelo normal do scikitlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bukbI0_KGSzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbkNWXd-MFwb",
        "colab_type": "code",
        "outputId": "4fe2daeb-63b0-4317-f9be-4e7d6e38dca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lr_clf = LogisticRegression(max_iter=1000)\n",
        "lr_clf.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULaX5C03MNq3",
        "colab_type": "code",
        "outputId": "d43e0e40-7211-4f34-c5d1-adadb7e3d498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHlLK_GpMi6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq2fa0DKbSH0",
        "colab_type": "text"
      },
      "source": [
        "# **Desafio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMUy14i2bVnA",
        "colab_type": "text"
      },
      "source": [
        "Conecte uma rede neural à saída do BERT e veja se consegue melhores resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLi6SFUMbVQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}