{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandsOn3 - BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DRSLima/sentiment-analysis-twitter/blob/master/HandsOn_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJJRtUb_QtFk",
        "colab_type": "code",
        "outputId": "16e965ab-d6ac-4226-c765-099bf9e16113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98dz7R9Qq4S",
        "colab_type": "code",
        "outputId": "7519689e-9ae5-4361-ad94-55bb25f079a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train = pd.read_csv('https://raw.githubusercontent.com/jpvmm/FASAM_NLP/master/train_sample.csv')\n",
        "\n",
        "#Vamos ter usar o subset menor pois a memória do notebook não vai aguentar.\n",
        "df_train = df_train[0:10000]\n",
        "\n",
        "\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/jpvmm/FASAM_NLP/master/test_sample.csv')\n",
        "\n",
        "df_test = df_test[0:500]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMuw9AFNHIk",
        "colab_type": "text"
      },
      "source": [
        "# **Começando os trabalhos**\n",
        "\n",
        "\n",
        "---\n",
        "**Pergunta**: Como podemos trabalhar com duas linguages diferentes? Qual estratégia poderia ser adotada utilizando o BERT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulpwhoOZROsy",
        "colab_type": "text"
      },
      "source": [
        "## **Utilizando DistilBERT**\n",
        "\n",
        "Vamos utilizar o DistilBERT da biblioteca Transformers HuggingFace.\n",
        "\n",
        "Aqui utilizaremos o modelo multilingual pré treinado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F35-jTTYM1u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-multilingual-cased')\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "modelo = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEax0xOqSQs9",
        "colab_type": "text"
      },
      "source": [
        "### **Limpeza e Tokenização**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlM15JbXTMz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df_train['title']\n",
        "y = df_train['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eccJfavUTXJJ",
        "colab_type": "code",
        "outputId": "3a50ad15-6cc6-48ff-d9e9-10d32834a9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Limpeza de dados\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def limpaTexto(texto):\n",
        "\n",
        "  tokens = texto.split()\n",
        "\n",
        "  #Regex para filtro de caracteres\n",
        "  re_puc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "  #Remoção de pontuação\n",
        "  tokens = [re_puc.sub('', w ) for w in tokens]\n",
        "  #Remoção de tokens não alfabéticos\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  #Remoção de stopwords\n",
        "  stop_words1 = set(stopwords.words('portuguese'))\n",
        "  stop_words2 = set(stopwords.words('spanish'))\n",
        "\n",
        "  tokens = [w for w in tokens if not w in stop_words1]\n",
        "  tokens = [w for w in tokens if not w in stop_words2]\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  tokens = ' '.join(tokens)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "x = x.apply(limpaTexto)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLeMChn3lsdx",
        "colab_type": "code",
        "outputId": "40601fcb-005b-4c72-9c34-bf8c2f825d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Visualizando como o BERT tokenizer sentenças\n",
        "#Wordpiece tokenization\n",
        "\n",
        "for i in range(3):\n",
        "  print(x[i], '---->', tokenizer.tokenize(x[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Microscópio Biológico Binocular Meopta Profissional ----> ['Micro', '##sc', '##ó', '##pio', 'Biol', '##ógico', 'Bin', '##oc', '##ular', 'Me', '##op', '##ta', 'Prof', '##ission', '##al']\n",
            "Nissan Versa ----> ['Nissan', 'Vers', '##a']\n",
            "Llave Contacto Yamaha Fz Tapa Tanque Mpr ----> ['L', '##lave', 'Contact', '##o', 'Yamaha', 'F', '##z', 'Ta', '##pa', 'Tan', '##que', 'M', '##pr']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J-iMGw_Rn_7",
        "colab_type": "code",
        "outputId": "3a03d36e-7c60-411b-8379-0c3b1b1e2aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tokenized = x.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "for i in range(3):\n",
        "  print(x[i],'--->', tokenized[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Microscópio Biológico Binocular Meopta Profissional ---> [101, 78857, 31505, 10443, 22196, 35992, 42151, 50754, 25125, 18062, 11589, 13362, 10213, 24864, 58334, 10415, 102]\n",
            "Nissan Versa ---> [101, 41650, 46744, 10113, 102]\n",
            "Llave Contacto Yamaha Fz Tapa Tanque Mpr ---> [101, 149, 57782, 77562, 10133, 56988, 143, 10305, 14248, 11359, 30594, 11189, 150, 52302, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_ag4JNSWR3",
        "colab_type": "code",
        "outputId": "e9152c4a-28e7-477a-91f1-03b58dd7f1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Criando o padding\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "padded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sftQZb_JUwi9",
        "colab_type": "text"
      },
      "source": [
        "### **Masking**\n",
        "pesquisar isso aqui"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbjWqlNUZiz",
        "colab_type": "code",
        "outputId": "4bf7685b-7b31-4689-8809-95fb56992418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nk8jm7VJm1d",
        "colab_type": "text"
      },
      "source": [
        "### **BERT Embeddings**\n",
        "\n",
        "Os embeddings do BERT são gerados a partir de sua última camada. \n",
        "\n",
        "Como estamos trabalhando com uma tarefa de classificação, apenas a posição com o token CLS é a que no interessa, pois é a posição da tarefa de classificação do BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lza4voWtUsgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = modelo(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTiXXd_uA7L2",
        "colab_type": "code",
        "outputId": "6e41786c-1357-4cba-d860-8b072af47960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_hidden_states[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 33, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6_32xY6LmZh",
        "colab_type": "text"
      },
      "source": [
        "**Pegando apenas o vetor de primeira posição na saída**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UGScNpxBEwu",
        "colab_type": "code",
        "outputId": "35672f4b-7886-4cd7-c881-d6d20922d482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ax1_sDLz3k",
        "colab_type": "text"
      },
      "source": [
        "## **Modelo de Classificação**\n",
        "\n",
        "Para realizar a tarefa de classificação, vamos utilizar um modelo normal do scikitlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bukbI0_KGSzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbkNWXd-MFwb",
        "colab_type": "code",
        "outputId": "4fe2daeb-63b0-4317-f9be-4e7d6e38dca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lr_clf = LogisticRegression(max_iter=1000)\n",
        "lr_clf.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULaX5C03MNq3",
        "colab_type": "code",
        "outputId": "d43e0e40-7211-4f34-c5d1-adadb7e3d498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHlLK_GpMi6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq2fa0DKbSH0",
        "colab_type": "text"
      },
      "source": [
        "# **Desafio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMUy14i2bVnA",
        "colab_type": "text"
      },
      "source": [
        "Conecte uma rede neural à saída do BERT e veja se consegue melhores resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REnBnvd17bl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 768\n",
        "max_seq_length = max_len\n",
        "\n",
        "# Reshape bert_output before passing it the GRU\n",
        "bert_output_ = tf.keras.layers.Reshape((max_seq_length, embedding_size))(last_hidden_states[0])\n",
        "gru_out = tf.keras.layers.GRU(100, activation='sigmoid')(bert_output_)\n",
        "dense = tf.keras.layers.Dense(256, activation=\"relu\")(gru_out)\n",
        "pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EmcgGWiBF7T",
        "colab_type": "code",
        "outputId": "2bacca8b-2732-4579-d63c-883c84121ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "input1 = tf.keras.Input(shape=(max_len, 33,), name='input1')\n",
        "\n",
        "modelo = tf.keras.Model(inputs=input1, outputs=pred)\n",
        "\n",
        "modelo.summary()\n",
        "\n",
        "modelo.compile(loss='categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "weights_filepath='./pesos.h5'\n",
        "\n",
        "callbacks = [ModelCheckpoint(weights_filepath, monitor='val_loss', mode='min',\n",
        "                             verbose=1, save_best_only=True),\n",
        "             EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             [(None, 33, 33)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_dense_5/Sigmoid (Te [(10000, 1)]         0                                            \n",
            "==================================================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF3H5ZGw2e_v",
        "colab_type": "code",
        "outputId": "7ad0cbb5-7038-4369-b093-01d67655dc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Separa o dataset em dados de treinamento/validação\n",
        "X_train, X_test, y_train, Y_test =  train_test_split(features, y)\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter=1000)\n",
        "lr_clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_5o4NEy__Nv",
        "colab_type": "code",
        "outputId": "0a1d9662-f280-42f9-8e29-6e8ee49c32a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCB7nWqaTKJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}